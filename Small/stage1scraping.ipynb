{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charity Scraper\n",
    "### The Plan:\n",
    "1. Stage 1 scraping: Scrape Each Charity's register_index URL from the main search page\n",
    "1. Stage 2 scraping: Open each charity and scrape characteristics\n",
    "1. Stage 3 analysis:\n",
    "  - clean date data\n",
    "  - Use generated charity_index to filter for websites with desired characteristics\n",
    "    * income\n",
    "    * reporting\n",
    "    * cause helped\n",
    "    * has website and charity_url\n",
    "\n",
    "## Stage 1 Scraping\n",
    "#### todo:\n",
    "- scrape 10 at a time\n",
    "- rerun\n",
    "- add placeholder headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation and loadup\n",
    "from http import server\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import selenium as sl\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "driverpath=ChromeDriverManager().install()\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "size = 'Small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the pandas dataframe\n",
    "columns = [\"Index_Link\", \"Legal_Name\", \"Town/Suburb\",\"State\", \"Status\", \"Size\",\"ABN\",\"Website\",\"Revenue\",\"Expenses\",\"Cause/s\",\"Last_report_date\",\"ref_religion\"]\n",
    "try:\n",
    "    os.mkdir('s1scrapedata')\n",
    "except:\n",
    "    None\n",
    "\n",
    "try:\n",
    "    os.mkdir('s2scrapedata')\n",
    "except:\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getpageurl(p):\n",
    "    lefturl=\"https://www.acnc.gov.au/charity/charities?items_per_page=100&page=\"\n",
    "    pagenumber=str(p)\n",
    "    righturl=\"&f[]=size%3A\"+size\n",
    "    \n",
    "    url = lefturl+pagenumber+righturl #pre filtered url for small businesses and to show 100 results - Page 1\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_page_data(d):\n",
    "    try:\n",
    "        WebDriverWait(d,90).until(EC.presence_of_element_located((By.TAG_NAME,\"tbody\")))\n",
    "        time.sleep(1)\n",
    "        table=d.find_element(by=By.TAG_NAME, value=\"tbody\")\n",
    "        rows=table.find_elements(by=By.TAG_NAME,value=\"tr\")\n",
    "        \n",
    "        for row in rows:\n",
    "            link   = row.find_element(by=By.TAG_NAME,value=\"a\").get_attribute(\"href\")\n",
    "            name   = row.find_elements(by=By.TAG_NAME, value=\"td\")[0].text\n",
    "            town   = row.find_elements(by=By.TAG_NAME, value=\"td\")[1].text\n",
    "            state  = row.find_elements(by=By.TAG_NAME, value=\"td\")[2].text\n",
    "            status = row.find_elements(by=By.TAG_NAME, value=\"td\")[3].text\n",
    "            size   = row.find_elements(by=By.TAG_NAME, value=\"td\")[4].text\n",
    "            abn    = row.find_elements(by=By.TAG_NAME, value=\"td\")[5].text\n",
    "\n",
    "            row_data = pd.DataFrame([link,name,town,state,status,size,abn,None,None,None,None,None,None], index=columns).transpose()\n",
    "            try:\n",
    "                page_data = pd.concat([page_data,row_data],ignore_index=True)\n",
    "            except:\n",
    "                page_data = row_data\n",
    "        \n",
    "        return page_data\n",
    "    except:\n",
    "        print('Table could not be found on page'+str(page))\n",
    "        return None \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   df=pd.DataFrame([0,1,'b'], index=[10,20,30]).transpose()\n",
    "#   b=pd.DataFrame([2,3,5], index=[10,20,30]).transpose()\n",
    "#   df=pd.concat([df,b],ignore_index=True)\n",
    "#   print(df)\n",
    "#   df=pd.concat([df,copy.deepcopy(b)],ignore_index=True)\n",
    "#   print(df)\n",
    "#   \n",
    "#   df.to_csv('./folder/file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n",
      "[[0 0 0]\n",
      " [1 2 3]]\n"
     ]
    }
   ],
   "source": [
    "a=np.array([0,0,0])\n",
    "print(a)\n",
    "a=np.vstack((a,[1,2,3]))\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_drivers(num_drivers=10):\n",
    "    drivers =[]\n",
    "    for i in range(num_drivers):\n",
    "        drivers.append(webdriver.Chrome(service=Service(driverpath)))\n",
    "    return drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scraper():\n",
    "    drivers = open_drivers(5)\n",
    "    try:\n",
    "        #navigate into pages and scrape\n",
    "        page=0\n",
    "        totalpages= 353 - 1 #actual pages-1\n",
    "        try:\n",
    "            ScrapedSearchPages = np.load('./s1scrapedata/scrapedpageindex.npy')\n",
    "        except:\n",
    "            ScrapedSearchPages = np.array([])\n",
    "\n",
    "        tempdf = pd.DataFrame()\n",
    "\n",
    "        while page < totalpages:\n",
    "            #load up sites\n",
    "            pagecopy = copy.deepcopy(page)\n",
    "            for d in drivers:\n",
    "                while pagecopy in ScrapedSearchPages:\n",
    "                    pagecopy+=1\n",
    "                if pagecopy < totalpages:\n",
    "                    d.get(getpageurl(pagecopy))        \n",
    "                    pagecopy+=1\n",
    "\n",
    "            ## scraping\n",
    "            for D in drivers:\n",
    "                while page in ScrapedSearchPages:\n",
    "                    page +=1\n",
    "                page_data = extract_page_data(d=D)\n",
    "                tempdf=pd.concat((tempdf,page_data),ignore_index=True)\n",
    "                ScrapedSearchPages=np.append(ScrapedSearchPages, page)\n",
    "\n",
    "                if (page+1) % 15 == 0:\n",
    "                    np.save('./s1scrapedata/scrapedpageindex.npy',ScrapedSearchPages)\n",
    "                    tempdf.to_csv('./s1scrapedata/S1scrape_topage'+str(page+1)+'.csv')\n",
    "                    tempdf = pd.DataFrame()\n",
    "    \n",
    "                page += 1\n",
    "                print(\"Progress: \"+str(page)+\"/\"+str(totalpages+1))\n",
    "\n",
    "        #final Save\n",
    "        np.save('./s1scrapedata/scrapedpageindex.npy',ScrapedSearchPages)\n",
    "        tempdf.to_csv('./s1scrapedata/S1scrape_topage'+str(page+1)+'.csv')\n",
    "        tempdf = pd.DataFrame()\n",
    "\n",
    "\n",
    "        #kill drivers\n",
    "        for d in drivers:\n",
    "            d.quit()\n",
    "\n",
    "    except Exception as e:\n",
    "        for d in drivers:\n",
    "            d.quit()\n",
    "        raise e\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 196/353\n",
      "Progress: 197/353\n",
      "Progress: 198/353\n",
      "Progress: 199/353\n",
      "Progress: 200/353\n",
      "Progress: 201/353\n",
      "Progress: 202/353\n",
      "Progress: 203/353\n",
      "Progress: 204/353\n",
      "Progress: 205/353\n",
      "Progress: 206/353\n",
      "Progress: 207/353\n",
      "Progress: 208/353\n",
      "Progress: 209/353\n",
      "Progress: 210/353\n",
      "Progress: 211/353\n",
      "Progress: 212/353\n",
      "Progress: 213/353\n",
      "Progress: 214/353\n",
      "Progress: 215/353\n",
      "Progress: 216/353\n",
      "Progress: 217/353\n",
      "Progress: 218/353\n",
      "Progress: 219/353\n",
      "Progress: 220/353\n",
      "Progress: 221/353\n",
      "Progress: 222/353\n",
      "Progress: 223/353\n",
      "Progress: 224/353\n",
      "Progress: 225/353\n",
      "Progress: 226/353\n",
      "Progress: 227/353\n",
      "Progress: 228/353\n",
      "Progress: 229/353\n",
      "Progress: 230/353\n",
      "Progress: 231/353\n",
      "Progress: 232/353\n",
      "Progress: 233/353\n",
      "Progress: 234/353\n",
      "Progress: 235/353\n",
      "Progress: 236/353\n",
      "Progress: 237/353\n",
      "Progress: 238/353\n",
      "Progress: 239/353\n",
      "Progress: 240/353\n",
      "Progress: 241/353\n",
      "Progress: 242/353\n",
      "Progress: 243/353\n",
      "Progress: 244/353\n",
      "Progress: 245/353\n",
      "Progress: 246/353\n",
      "Progress: 247/353\n",
      "Progress: 248/353\n",
      "Progress: 249/353\n",
      "Progress: 250/353\n",
      "Progress: 251/353\n",
      "Progress: 252/353\n",
      "Progress: 253/353\n",
      "Progress: 254/353\n",
      "Progress: 255/353\n",
      "Progress: 256/353\n",
      "Progress: 257/353\n",
      "Progress: 258/353\n",
      "Progress: 259/353\n",
      "Progress: 260/353\n",
      "Progress: 261/353\n",
      "Progress: 262/353\n",
      "Progress: 263/353\n",
      "Progress: 264/353\n",
      "Progress: 265/353\n",
      "Progress: 266/353\n",
      "Progress: 267/353\n",
      "Progress: 268/353\n",
      "Progress: 269/353\n",
      "Progress: 270/353\n",
      "Progress: 271/353\n",
      "Progress: 272/353\n",
      "Progress: 273/353\n",
      "Progress: 274/353\n",
      "Progress: 275/353\n",
      "Progress: 276/353\n",
      "Progress: 277/353\n",
      "Progress: 278/353\n",
      "Progress: 279/353\n",
      "Progress: 280/353\n",
      "Progress: 281/353\n",
      "Progress: 282/353\n",
      "Progress: 283/353\n",
      "Progress: 284/353\n",
      "Progress: 285/353\n",
      "Progress: 286/353\n",
      "Progress: 287/353\n",
      "Progress: 288/353\n",
      "Progress: 289/353\n",
      "Progress: 290/353\n",
      "Progress: 291/353\n",
      "Progress: 292/353\n",
      "Progress: 293/353\n",
      "Progress: 294/353\n",
      "Progress: 295/353\n",
      "Progress: 296/353\n",
      "Progress: 297/353\n",
      "Progress: 298/353\n",
      "Progress: 299/353\n",
      "Progress: 300/353\n",
      "Progress: 301/353\n",
      "Progress: 302/353\n",
      "Progress: 303/353\n",
      "Progress: 304/353\n",
      "Progress: 305/353\n",
      "Progress: 306/353\n",
      "Progress: 307/353\n",
      "Progress: 308/353\n",
      "Progress: 309/353\n",
      "Progress: 310/353\n",
      "Progress: 311/353\n",
      "Progress: 312/353\n",
      "Progress: 313/353\n",
      "Progress: 314/353\n",
      "Progress: 315/353\n",
      "Progress: 316/353\n",
      "Progress: 317/353\n",
      "Progress: 318/353\n",
      "Progress: 319/353\n",
      "Progress: 320/353\n",
      "Progress: 321/353\n",
      "Progress: 322/353\n",
      "Progress: 323/353\n",
      "Progress: 324/353\n",
      "Progress: 325/353\n",
      "Progress: 326/353\n",
      "Progress: 327/353\n",
      "Progress: 328/353\n",
      "Progress: 329/353\n",
      "Progress: 330/353\n",
      "Progress: 331/353\n",
      "Progress: 332/353\n",
      "Progress: 333/353\n",
      "Progress: 334/353\n",
      "Progress: 335/353\n",
      "Progress: 336/353\n",
      "Progress: 337/353\n",
      "Progress: 338/353\n",
      "Progress: 339/353\n",
      "Progress: 340/353\n",
      "Progress: 341/353\n",
      "Progress: 342/353\n",
      "Progress: 343/353\n",
      "Progress: 344/353\n",
      "Progress: 345/353\n",
      "Progress: 346/353\n",
      "Progress: 347/353\n",
      "Progress: 348/353\n",
      "Progress: 349/353\n",
      "Progress: 350/353\n",
      "Progress: 351/353\n",
      "Progress: 352/353\n",
      "Progress: 353/353\n",
      "Progress: 354/353\n",
      "Progress: 355/353\n"
     ]
    }
   ],
   "source": [
    "run_scraper()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
